{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWIzrv94Q5U4",
        "outputId": "af2eb0ed-7b3d-4ccc-f3d6-d38c084974de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov  3 19:49:03 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello from GPU thread %d\\n\", threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    hello<<<1,5>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"Hello from CPU\\n\");\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMyY09ePRBJp",
        "outputId": "9c0cc447-a470-434e-cc97-694dbd627e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 hello.cu -o hello\n",
        "!./hello\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyFJCZQBRPxE",
        "outputId": "c823a950-26eb-4630-f05b-5e9e85b42a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile blockIdx.cu\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void block(){\n",
        "  int t = threadIdx.x;\n",
        "  int b = blockIdx.x;\n",
        "  printf(\"Thread %d in block %d\\n\", t, b);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  block<<<3,5>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmXdDV7CRURk",
        "outputId": "bffaa902-0a5a-45a2-bb0f-a101d45d57c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting blockIdx.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 blockIdx.cu"
      ],
      "metadata": {
        "id": "sOHl1SxhTNor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpyNhkHuTRoW",
        "outputId": "4323a20a-709d-4352-e7c7-da14df854ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 in block 1\n",
            "Thread 1 in block 1\n",
            "Thread 2 in block 1\n",
            "Thread 3 in block 1\n",
            "Thread 4 in block 1\n",
            "Thread 0 in block 2\n",
            "Thread 1 in block 2\n",
            "Thread 2 in block 2\n",
            "Thread 3 in block 2\n",
            "Thread 4 in block 2\n",
            "Thread 0 in block 0\n",
            "Thread 1 in block 0\n",
            "Thread 2 in block 0\n",
            "Thread 3 in block 0\n",
            "Thread 4 in block 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile d.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void d() {\n",
        "    int x = threadIdx.x;\n",
        "    int y = threadIdx.y;\n",
        "    printf(\"Thread (%d,%d) in Block (%d,%d)\\n\", x, y, blockIdx.x, blockIdx.y);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    dim3 grid(2, 2);      // 2x2 blocks\n",
        "    dim3 block(2, 2);     // 2x2 threads per block\n",
        "\n",
        "    d<<<grid, block>>>(); // Correct launch syntax\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "YbxoOSq3ViXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b395a7d6-2d52-4d6d-ed34-6e20d981b6b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 d.cu"
      ],
      "metadata": {
        "id": "71aAXgllTvx3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQTcYtwEUOfu",
        "outputId": "ed51322f-76af-4e70-bd3a-617d05dc999b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread (0,0) in Block (1,0)\n",
            "Thread (1,0) in Block (1,0)\n",
            "Thread (0,1) in Block (1,0)\n",
            "Thread (1,1) in Block (1,0)\n",
            "Thread (0,0) in Block (1,1)\n",
            "Thread (1,0) in Block (1,1)\n",
            "Thread (0,1) in Block (1,1)\n",
            "Thread (1,1) in Block (1,1)\n",
            "Thread (0,0) in Block (0,1)\n",
            "Thread (1,0) in Block (0,1)\n",
            "Thread (0,1) in Block (0,1)\n",
            "Thread (1,1) in Block (0,1)\n",
            "Thread (0,0) in Block (0,0)\n",
            "Thread (1,0) in Block (0,0)\n",
            "Thread (0,1) in Block (0,0)\n",
            "Thread (1,1) in Block (0,0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vecAdd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void addVectors(float *A, float *B, float *C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N)\n",
        "        C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "// CPU version\n",
        "void addVectorsCPU(float *A, float *B, float *C, int N) {\n",
        "    for (int i = 0; i < N; i++)\n",
        "        C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int sizes[] = {100000, 1000000, 10000000}; // 10^5, 10^6, 10^7\n",
        "    int testCount = sizeof(sizes) / sizeof(sizes[0]);\n",
        "\n",
        "    for (int t = 0; t < testCount; t++) {\n",
        "        int N = sizes[t];\n",
        "        size_t bytes = N * sizeof(float);\n",
        "\n",
        "        printf(\"\\n=================================\\n\");\n",
        "        printf(\"Vector Size: %d\\n\", N);\n",
        "\n",
        "        // Allocate memory on host\n",
        "        float *h_A = (float*)malloc(bytes);\n",
        "        float *h_B = (float*)malloc(bytes);\n",
        "        float *h_C_cpu = (float*)malloc(bytes);\n",
        "        float *h_C_gpu = (float*)malloc(bytes);\n",
        "\n",
        "        // Initialize input vectors with random numbers\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            h_A[i] = rand() % 100;\n",
        "            h_B[i] = rand() % 100;\n",
        "        }\n",
        "\n",
        "        // ===================== CPU computation =====================\n",
        "        clock_t start_cpu = clock();\n",
        "        addVectorsCPU(h_A, h_B, h_C_cpu, N);\n",
        "        clock_t end_cpu = clock();\n",
        "        double cpu_time = (double)(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "        // ===================== GPU computation =====================\n",
        "        float *d_A, *d_B, *d_C;\n",
        "        cudaMalloc((void**)&d_A, bytes);\n",
        "        cudaMalloc((void**)&d_B, bytes);\n",
        "        cudaMalloc((void**)&d_C, bytes);\n",
        "\n",
        "        cudaMemcpy(d_A, h_A, bytes, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_B, h_B, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "        int threads = 256;\n",
        "        int blocks = (N + threads - 1) / threads;\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        addVectors<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        float gpu_time_ms = 0;\n",
        "        cudaEventElapsedTime(&gpu_time_ms, start, stop); // in milliseconds\n",
        "\n",
        "        cudaMemcpy(h_C_gpu, d_C, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // ===================== Verify result =====================\n",
        "        int correct = 1;\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            if (fabs(h_C_cpu[i] - h_C_gpu[i]) > 1e-5) {\n",
        "                correct = 0;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // ===================== Print results =====================\n",
        "        printf(\"CPU Time: %.6f s\\n\", cpu_time);\n",
        "        printf(\"GPU Time: %.6f s\\n\", gpu_time_ms / 1000.0);\n",
        "        printf(\"Speedup: %.2fx\\n\", cpu_time / (gpu_time_ms / 1000.0));\n",
        "        printf(\"Result Verification: %s\\n\", correct ? \"PASSED ✅\" : \"FAILED ❌\");\n",
        "\n",
        "        // ===================== Free memory =====================\n",
        "        cudaFree(d_A);\n",
        "        cudaFree(d_B);\n",
        "        cudaFree(d_C);\n",
        "        free(h_A);\n",
        "        free(h_B);\n",
        "        free(h_C_cpu);\n",
        "        free(h_C_gpu);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "lxXAyHUWUQeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b12871-aaf3-4705-e66f-ed05bdb054be"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vecAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 vecAdd.cu"
      ],
      "metadata": {
        "id": "TG1QBCASYYAL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAhN6wO1Yai3",
        "outputId": "8f482f20-4dfd-4c94-e783-605223880ff0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================\n",
            "Vector Size: 100000\n",
            "CPU Time: 0.000447 s\n",
            "GPU Time: 0.000106 s\n",
            "Speedup: 4.22x\n",
            "Result Verification: PASSED ✅\n",
            "\n",
            "=================================\n",
            "Vector Size: 1000000\n",
            "CPU Time: 0.004563 s\n",
            "GPU Time: 0.000052 s\n",
            "Speedup: 87.32x\n",
            "Result Verification: PASSED ✅\n",
            "\n",
            "=================================\n",
            "Vector Size: 10000000\n",
            "CPU Time: 0.053648 s\n",
            "GPU Time: 0.000463 s\n",
            "Speedup: 115.80x\n",
            "Result Verification: PASSED ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matAdd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define M 1000   // number of rows\n",
        "#define N 1000   // number of columns\n",
        "\n",
        "__global__ void matrixAdd(float *A, float *B, float *C, int rows, int cols) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < rows && col < cols) {\n",
        "        int idx = row * cols + col;\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU version of matrix addition\n",
        "void matrixAddCPU(float *A, float *B, float *C, int rows, int cols) {\n",
        "    for (int i = 0; i < rows * cols; i++) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = M * N * sizeof(float);\n",
        "\n",
        "    float *A, *B, *C, *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Allocate memory on host (CPU)\n",
        "    A = (float *)malloc(size);\n",
        "    B = (float *)malloc(size);\n",
        "    C = (float *)malloc(size);\n",
        "\n",
        "    // Initialize matrices A and B with random numbers\n",
        "    for (int i = 0; i < M * N; i++) {\n",
        "        A[i] = rand() % 100;\n",
        "        B[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on device (GPU)\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy A and B to device\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid size\n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((N + blockSize.x - 1) / blockSize.x,\n",
        "                  (M + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    // Measure GPU time\n",
        "    clock_t start_gpu = clock();\n",
        "    matrixAdd<<<gridSize, blockSize>>>(d_A, d_B, d_C, M, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    clock_t end_gpu = clock();\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Measure CPU time\n",
        "    clock_t start_cpu = clock();\n",
        "    matrixAddCPU(A, B, C, M, N);\n",
        "    clock_t end_cpu = clock();\n",
        "\n",
        "    // Compute execution times\n",
        "    double cpu_time = (double)(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "    double gpu_time = (double)(end_gpu - start_gpu) / CLOCKS_PER_SEC;\n",
        "    double speedup = cpu_time / gpu_time;\n",
        "\n",
        "    printf(\"Matrix size: %d x %d\\n\", M, N);\n",
        "    printf(\"CPU Time: %.6f seconds\\n\", cpu_time);\n",
        "    printf(\"GPU Time: %.6f seconds\\n\", gpu_time);\n",
        "    printf(\"Speedup: %.2fx\\n\", speedup);\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9NKzF_rYb3R",
        "outputId": "362e09c6-08ff-4137-f4f1-f1a9a5f6f5b4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 matAdd.cu"
      ],
      "metadata": {
        "id": "X9ubdyoFdKSm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owUqV-_edTzN",
        "outputId": "f75c29d2-8790-4c1c-cc3a-4a8d8114b75f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 1000 x 1000\n",
            "CPU Time: 0.003201 seconds\n",
            "GPU Time: 0.000193 seconds\n",
            "Speedup: 16.59x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile DotProd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define N (2048 * 2048)          // Total number of elements\n",
        "#define THREADS_PER_BLOCK 512    // Threads per block\n",
        "\n",
        "// CUDA kernel for parallel dot product\n",
        "__global__ void dot(int *a, int *b, int *c) {\n",
        "    __shared__ int temp[THREADS_PER_BLOCK];\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // Each thread computes its partial product\n",
        "    temp[tid] = a[index] * b[index];\n",
        "    __syncthreads();\n",
        "\n",
        "    // Only thread 0 in each block sums up and updates global result\n",
        "    if (tid == 0) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < THREADS_PER_BLOCK; i++)\n",
        "            sum += temp[i];\n",
        "        atomicAdd(c, sum);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to fill array with random integers\n",
        "void random_ints(int *x, int n) {\n",
        "    for (int i = 0; i < n; i++)\n",
        "        x[i] = rand() % 10;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int *a, *b, *c;             // Host copies\n",
        "    int *dev_a, *dev_b, *dev_c; // Device copies\n",
        "    int size = N * sizeof(int);\n",
        "    float cpu_time, gpu_time;\n",
        "\n",
        "    // Allocate memory on device\n",
        "    cudaMalloc((void**)&dev_a, size);\n",
        "    cudaMalloc((void**)&dev_b, size);\n",
        "    cudaMalloc((void**)&dev_c, sizeof(int));\n",
        "\n",
        "    // Allocate memory on host\n",
        "    a = (int*)malloc(size);\n",
        "    b = (int*)malloc(size);\n",
        "    c = (int*)malloc(sizeof(int));\n",
        "\n",
        "    // Initialize input vectors\n",
        "    random_ints(a, N);\n",
        "    random_ints(b, N);\n",
        "    *c = 0;\n",
        "\n",
        "    /* ---------------- CPU Implementation ---------------- */\n",
        "    clock_t start_cpu = clock();\n",
        "    long long cpu_result = 0;\n",
        "    for (int i = 0; i < N; i++)\n",
        "        cpu_result += (long long)a[i] * b[i];\n",
        "    clock_t end_cpu = clock();\n",
        "    cpu_time = ((float)(end_cpu - start_cpu)) / CLOCKS_PER_SEC * 1000.0; // in ms\n",
        "\n",
        "    /* ---------------- GPU Implementation ---------------- */\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_c, c, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    dot<<<N / THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>(dev_a, dev_b, dev_c);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaMemcpy(c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "\n",
        "    /* ---------------- Results ---------------- */\n",
        "    printf(\"CPU Dot Product  = %lld\\n\", cpu_result);\n",
        "    printf(\"GPU Dot Product  = %d\\n\", *c);\n",
        "    printf(\"CPU Time = %.3f ms\\n\", cpu_time);\n",
        "    printf(\"GPU Time = %.3f ms\\n\", gpu_time);\n",
        "    printf(\"Speedup  = %.2fx\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    /* ---------------- Cleanup ---------------- */\n",
        "    free(a); free(b); free(c);\n",
        "    cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c);\n",
        "    cudaEventDestroy(start); cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPzQvWAgdV6O",
        "outputId": "77c85b6c-26c7-44e9-af37-d814387c9770"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing DotProd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arcsm_70 DotProd.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnQJf7DOfP3d",
        "outputId": "99cd9cb8-32bb-4061-e735-56f6375550b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc fatal   : Unknown option '-arcsm_70'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSHMTeiNfVNG",
        "outputId": "9af425d5-172b-40f6-9e7c-4106f2665f23"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 1000 x 1000\n",
            "CPU Time: 0.003163 seconds\n",
            "GPU Time: 0.000172 seconds\n",
            "Speedup: 18.39x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile MatMat.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define M 512   // Rows in A and C\n",
        "#define N 512   // Columns in A, Rows in B\n",
        "#define P 512   // Columns in B and C\n",
        "\n",
        "// CUDA kernel for Matrix Multiplication\n",
        "__global__ void matrixMulKernel(float *A, float *B, float *C, int M, int N, int P) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0;\n",
        "\n",
        "    if (row < M && col < P) {\n",
        "        for (int k = 0; k < N; ++k)\n",
        "            sum += A[row * N + k] * B[k * P + col];\n",
        "        C[row * P + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to fill matrix with random floats\n",
        "void random_matrix(float *mat, int rows, int cols) {\n",
        "    for (int i = 0; i < rows * cols; i++)\n",
        "        mat[i] = (float)(rand() % 10);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size_A = M * N * sizeof(float);\n",
        "    int size_B = N * P * sizeof(float);\n",
        "    int size_C = M * P * sizeof(float);\n",
        "\n",
        "    float *A, *B, *C_cpu, *C_gpu;\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    A = (float*)malloc(size_A);\n",
        "    B = (float*)malloc(size_B);\n",
        "    C_cpu = (float*)malloc(size_C);\n",
        "    C_gpu = (float*)malloc(size_C);\n",
        "\n",
        "    random_matrix(A, M, N);\n",
        "    random_matrix(B, N, P);\n",
        "\n",
        "    /* ---------------- CPU Implementation ---------------- */\n",
        "    clock_t start_cpu = clock();\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < P; j++) {\n",
        "            float sum = 0.0;\n",
        "            for (int k = 0; k < N; k++)\n",
        "                sum += A[i * N + k] * B[k * P + j];\n",
        "            C_cpu[i * P + j] = sum;\n",
        "        }\n",
        "    }\n",
        "    clock_t end_cpu = clock();\n",
        "    float cpu_time = ((float)(end_cpu - start_cpu)) / CLOCKS_PER_SEC * 1000.0; // in ms\n",
        "\n",
        "    /* ---------------- GPU Implementation ---------------- */\n",
        "    cudaMalloc((void**)&d_A, size_A);\n",
        "    cudaMalloc((void**)&d_B, size_B);\n",
        "    cudaMalloc((void**)&d_C, size_C);\n",
        "\n",
        "    cudaMemcpy(d_A, A, size_A, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size_B, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((P + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMulKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, M, N, P);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaMemcpy(C_gpu, d_C, size_C, cudaMemcpyDeviceToHost);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_time;\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "\n",
        "    /* ---------------- Speedup and Output ---------------- */\n",
        "    printf(\"CPU Time = %.3f ms\\n\", cpu_time);\n",
        "    printf(\"GPU Time = %.3f ms\\n\", gpu_time);\n",
        "    printf(\"Speedup  = %.2fx\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    /* ---------------- Cleanup ---------------- */\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C_cpu);\n",
        "    free(C_gpu);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIoOGAwXfWND",
        "outputId": "f303f4e8-6594-404b-d211-c11a907c67f0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing MatMat.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fv5BUF2sfgYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}